import { Composition } from 'remotion';
import { Intro, calculateIntroDuration } from './compositions/Intro';
import { Main, calculateTotalDuration, type MainProps } from './compositions/Main';
import { Step1, calculateStep1Duration } from './compositions/Step1';
import { Step2, calculateStep2Duration } from './compositions/Step2';
import { Step3, calculateStep3Duration } from './compositions/Step3';
import { Step4, calculateStep4Duration } from './compositions/Step4';
import { StepTransition, STEP_TRANSITION_DURATION } from './compositions/StepTransition';
import { Ending, ENDING_DURATION } from './compositions/Ending';
import {
  FillInBlankShorts,
  calculateFillInBlankShortsDuration,
} from './compositions/FillInBlankShorts';
import {
  SingleSentenceShort,
  calculateSingleSentenceShortDuration,
} from './compositions/SingleSentenceShort';
import {
  ListeningQuizShort,
  calculateListeningQuizShortDuration,
  generateQuizChoices,
} from './compositions/ListeningQuizShort';
import { CatInterviewShort, calculateCatInterviewDuration } from './compositions/CatInterviewShort';
import {
  ComparisonLongform,
  calculateTotalDuration as calculateComparisonDuration,
  getVideoTiming,
} from './compositions/ComparisonLongform';
import { ComparisonView } from './compositions/ComparisonView';
import { HookIntro } from './compositions/HookIntro';
import { CTAEnding } from './compositions/CTAEnding';
import { createSampleComparisonScript } from './comparison/sample';
import type { TimingProfileType } from './comparison/timing-profile';
import type { ChannelConfig } from './config/types';
import type { Script } from './script/types';
import type { AudioFile } from './tts/types';

// =============================================================================
// Dynamic Loading from public/ folder
// When running "npm run start", place these files in public/:
//   - script.json (from output folder)
//   - config.json (from channels/ folder)
//   - audio/manifest.json (from output folder)
//   - background.png
//   - assets/ folder
// =============================================================================

// Try to load dynamic data from public/ folder
let dynamicScript: Script | null = null;
let dynamicConfig: ChannelConfig | null = null;
let dynamicAudioFiles: AudioFile[] | null = null;

// ComparisonScript for ComparisonLongform compositions
import type { ComparisonScript } from './comparison/types';
let dynamicComparisonScript: ComparisonScript | null = null;

try {
  // These will be loaded at build time if files exist in public/
  dynamicScript = require('../public/script.json') as Script;
  dynamicConfig = require('../public/config.json') as ChannelConfig;
  const rawAudioFiles = require('../public/audio/manifest.json') as AudioFile[];
  // Convert paths to relative paths for staticFile()
  dynamicAudioFiles = rawAudioFiles.map((af) => ({
    ...af,
    path: `audio/${af.path.split('/').pop()}`,
  }));
  console.log('âœ… Loaded dynamic data from public/ folder');
} catch {
  console.log('â„¹ï¸ Using sample data (no dynamic data in public/)');
}

// Try to load ComparisonScript separately (for ComparisonLongform)
try {
  const rawScript = require('../public/script.json');
  // Check if it's a ComparisonScript by looking for 'segments' with ComparisonSegment structure
  if (rawScript.segments && rawScript.segments[0]?.koreanExpression) {
    dynamicComparisonScript = rawScript as ComparisonScript;
    console.log('âœ… Loaded ComparisonScript from public/ folder');
  }
} catch {
  // Ignore - will use sample data
}

// TTS duration (ì‹¤ì œ íŒŒì¼ì—ì„œ ì¸¡ì •ëœ ê°’)
const VIRAL_TTS_DURATION = 5.256;
const GUIDE_TTS_DURATION = 3.936;
const STEP_TTS_DURATIONS = [8.52, 8.904, 9.72, 7.464];
const CLOSING_TTS_DURATION = 2.952;

// Sample config for preview
const sampleConfig: ChannelConfig = {
  channelId: 'english',
  meta: {
    name: 'ê·€ê°€ ëš«ë¦¬ëŠ” ì˜ì–´',
    targetLanguage: 'English',
    nativeLanguage: 'Korean',
  },
  theme: {
    logo: 'english/logo.png',
    introSound: 'english/intro.mp3',
    backgroundStyle: 'gradient',
    primaryColor: '#FFD700',
    secondaryColor: '#1E90FF',
  },
  colors: {
    maleText: '#4A90D9',
    femaleText: '#E91E8C',
    nativeText: '#FFFFFF',
    wordMeaning: '#AAAAAA',
    background: '#000000',
  },
  layout: {
    step3ImageRatio: 0.4,
    subtitlePosition: 'center',
    speakerIndicator: 'left',
  },
  tts: {
    provider: 'openai',
    maleVoice: 'onyx',
    femaleVoice: 'nova',
    targetLanguageCode: 'en-US',
    speed: 1.0,
  },
  content: {
    sentenceCount: 6,
    repeatCount: 3,
    difficulty: 'beginner',
  },
  uiLabels: {
    introTitle: 'ì˜¤ëŠ˜ì˜ í•™ìŠµ',
    // Step titles (for intro and step indicators)
    step1Title: 'ì „ì²´ íë¦„ íŒŒì•… (ìë§‰ ì—†ì´ ë“£ê¸°)',
    step2Title: 'ìë§‰ìœ¼ë¡œ ë‚´ìš© ì´í•´ í•˜ê¸°',
    step3Title: '3ë‹¨ê³„ ë°˜ë³µ ë“£ê¸°',
    step4Title: 'ê¸°ì ì˜ ìˆœê°„ (ë‹¤ì‹œ ìë§‰ ì—†ì´ ë“£ê¸°)',
    // Step descriptions (for intro)
    step1Desc: 'ìë§‰ ì—†ì´ ì†Œë¦¬ì—ë§Œ ì§‘ì¤‘í•˜ë©°, ìƒí™©ì„ ìƒìƒí•´ë³´ì„¸ìš”.',
    step2Desc: 'ìë§‰ê³¼ í•¨ê»˜ ë“¤ìœ¼ë©°, ì•ˆ ë“¤ë ¸ë˜ ë¶€ë¶„ì„ í™•ì¸í•˜ì„¸ìš”.',
    step3Desc: '[ëŠë¦¬ê²Œ-ë¹ˆì¹¸-ë¹ ë¥´ê²Œ] ë°˜ë³µìœ¼ë¡œ ì˜ì–´ê°€ ë“¤ë¦¬ê¸° ì‹œì‘í•´ìš”.',
    step4Desc: 'ë†€ëê²Œ ì„ ëª…í•´ì§„ ì˜ì–´ë¥¼ ì§ì ‘ í™•ì¸í•´ë³´ì„¸ìš”!',
    // Step3 phase labels
    step3PhaseTitle: 'STEP 3 Â· ë°˜ë³µ í›ˆë ¨',
    phaseIntro: 'ğŸ§ ì²œì²œíˆ ë“£ê¸°',
    phaseTraining: 'ğŸ§© ë¹ˆì¹¸ í€´ì¦ˆ',
    phaseChallenge: 'âš¡ ë¹ ë¥´ê²Œ ë“£ê¸°',
    phaseReview: 'âœ¨ ë§ˆë¬´ë¦¬',
  },
  thumbnail: {
    channelName: 'ë“¤ë ¤ìš”! English!',
    characterStyle: 'custom',
    customCharacters: 'a friendly Caucasian man and a cheerful Korean woman',
    backgroundColor: 'dark blue',
  },
};

// Sample script for preview
const sampleScript: Script = {
  channelId: 'english',
  date: '2026-01-08',
  category: 'conversation',
  metadata: {
    topic: 'Morning Coffee',
    style: 'casual',
    title: {
      target: 'Morning Coffee Chat',
      native: 'ì•„ì¹¨ ì»¤í”¼ ëŒ€í™”',
    },
    characters: [
      {
        id: 'M' as const,
        name: 'James',
        gender: 'male' as const,
        ethnicity: 'American',
        role: 'friend',
      },
      {
        id: 'F' as const,
        name: 'Soo-jin',
        gender: 'female' as const,
        ethnicity: 'Korean',
        role: 'friend',
      },
    ],
  },
  sentences: [
    {
      id: 1,
      speaker: 'M',
      target: 'Good morning! Would you like some coffee?',
      targetBlank: 'Good morning! Would you like some _______?',
      blankAnswer: 'coffee',
      native: 'ì¢‹ì€ ì•„ì¹¨ì´ì—ìš”! ì»¤í”¼ ë“œì‹¤ë˜ìš”?',
      words: [
        { word: 'morning', meaning: 'ì•„ì¹¨' },
        { word: 'coffee', meaning: 'ì»¤í”¼' },
      ],
    },
    {
      id: 2,
      speaker: 'F',
      target: 'Yes, please. I need my morning caffeine.',
      targetBlank: 'Yes, please. I need my morning _______.',
      blankAnswer: 'caffeine',
      native: 'ë„¤, ì£¼ì„¸ìš”. ì•„ì¹¨ ì¹´í˜ì¸ì´ í•„ìš”í•´ìš”.',
      words: [
        { word: 'please', meaning: 'ì œë°œ, ë¶€íƒí•´ìš”' },
        { word: 'caffeine', meaning: 'ì¹´í˜ì¸' },
      ],
    },
    {
      id: 3,
      speaker: 'M',
      target: 'How do you take your coffee?',
      targetBlank: 'How do you _______ your coffee?',
      blankAnswer: 'take',
      native: 'ì»¤í”¼ ì–´ë–»ê²Œ ë“œì„¸ìš”?',
      words: [
        { word: 'take', meaning: '(ìŒë£Œë¥¼) ë§ˆì‹œë‹¤' },
        { word: 'coffee', meaning: 'ì»¤í”¼' },
      ],
    },
    {
      id: 4,
      speaker: 'F',
      target: 'Just black, no sugar.',
      targetBlank: 'Just black, no _______.',
      blankAnswer: 'sugar',
      native: 'ê·¸ëƒ¥ ë¸”ë™ìœ¼ë¡œìš”, ì„¤íƒ• ì—†ì´ìš”.',
      words: [
        { word: 'black', meaning: 'ë¸”ë™ (ì»¤í”¼)' },
        { word: 'sugar', meaning: 'ì„¤íƒ•' },
      ],
    },
    {
      id: 5,
      speaker: 'M',
      target: "That's the best way to enjoy it.",
      targetBlank: "That's the best way to _______ it.",
      blankAnswer: 'enjoy',
      native: 'ê·¸ê²Œ ê°€ì¥ ì¢‹ì€ ë°©ë²•ì´ì£ .',
      words: [
        { word: 'best', meaning: 'ìµœê³ ì˜' },
        { word: 'enjoy', meaning: 'ì¦ê¸°ë‹¤' },
      ],
    },
    {
      id: 6,
      speaker: 'F',
      target: 'I agree. It tastes so much better.',
      targetBlank: 'I agree. It _______ so much better.',
      blankAnswer: 'tastes',
      native: 'ë™ì˜í•´ìš”. í›¨ì”¬ ë§›ìˆì–´ìš”.',
      words: [
        { word: 'agree', meaning: 'ë™ì˜í•˜ë‹¤' },
        { word: 'tastes', meaning: 'ë§›ì´ ë‚˜ë‹¤' },
      ],
    },
  ],
};

// Sample audio files (mock data for preview - no actual audio)
const sampleAudioFiles: AudioFile[] = sampleScript.sentences.flatMap((sentence) => [
  {
    sentenceId: sentence.id,
    speaker: sentence.speaker,
    speed: '0.8x' as const,
    path: '',
    duration: 3.5,
  },
  {
    sentenceId: sentence.id,
    speaker: sentence.speaker,
    speed: '1.0x' as const,
    path: '',
    duration: 3.0,
  },
  {
    sentenceId: sentence.id,
    speaker: sentence.speaker,
    speed: '1.2x' as const,
    path: '',
    duration: 2.5,
  },
]);

// =============================================================================
// Use dynamic data if available, otherwise fall back to sample data
// =============================================================================
const activeConfig = dynamicConfig ?? sampleConfig;
const activeScript = dynamicScript ?? sampleScript;
const activeAudioFiles = dynamicAudioFiles ?? sampleAudioFiles;

// Calculate durations
const step1Duration = calculateStep1Duration(activeAudioFiles);
const step2Duration = calculateStep2Duration(activeScript.sentences, activeAudioFiles);
const step3Duration = calculateStep3Duration(
  activeScript.sentences,
  activeAudioFiles,
  activeConfig.content.repeatCount
);
const step4Duration = calculateStep4Duration(activeAudioFiles);

// ë™ì  ì¸íŠ¸ë¡œ ê¸¸ì´ ê³„ì‚°
const introDuration = calculateIntroDuration(
  VIRAL_TTS_DURATION,
  GUIDE_TTS_DURATION,
  STEP_TTS_DURATIONS,
  CLOSING_TTS_DURATION
);
const totalDuration = calculateTotalDuration(
  activeScript.sentences,
  activeAudioFiles,
  activeConfig.content.repeatCount,
  VIRAL_TTS_DURATION,
  GUIDE_TTS_DURATION,
  STEP_TTS_DURATIONS,
  CLOSING_TTS_DURATION
);

// calculateMetadata function for Main composition (ì™¸ë¶€ë¡œ ì¶”ì¶œí•˜ì—¬ ESLint prop-types ìš°íšŒ)
const calculateMainMetadata = ({ props }: { props: MainProps }) => {
  const actualDuration = calculateTotalDuration(
    props.script.sentences,
    props.audioFiles,
    props.config.content.repeatCount,
    props.viralNarrationDuration,
    props.guideNarrationDuration,
    props.stepNarrationDurations,
    props.closingNarrationDuration
  );
  return {
    durationInFrames: actualDuration,
  };
};

export const RemotionRoot: React.FC = () => {
  // Asset path prefix based on active config
  const assetPrefix = `assets/`;
  // const assetPrefix = `assets/${activeConfig.channelId}`;

  return (
    <>
      {/* Full Video - All Steps */}
      <Composition
        id="Main"
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        component={Main as any}
        durationInFrames={totalDuration}
        fps={30}
        width={1920}
        height={1080}
        defaultProps={{
          config: activeConfig,
          script: activeScript,
          audioFiles: activeAudioFiles,
          backgroundImage: 'background.png',
          thumbnailPath: `${assetPrefix}/thumbnail.png`,
          viralNarrationPath: `${assetPrefix}/intro-viral.mp3`,
          viralNarrationDuration: VIRAL_TTS_DURATION,
          guideNarrationPath: `${assetPrefix}/intro-narration.mp3`,
          guideNarrationDuration: GUIDE_TTS_DURATION,
          stepNarrationPaths: [
            `${assetPrefix}/intro-step1.mp3`,
            `${assetPrefix}/intro-step2.mp3`,
            `${assetPrefix}/intro-step3.mp3`,
            `${assetPrefix}/intro-step4.mp3`,
          ],
          stepNarrationDurations: STEP_TTS_DURATIONS,
          closingNarrationPath: `${assetPrefix}/intro-closing.mp3`,
          closingNarrationDuration: CLOSING_TTS_DURATION,
          stepTransitionTtsPaths: [
            `${assetPrefix}/step-transition-1.mp3`,
            `${assetPrefix}/step-transition-2.mp3`,
            `${assetPrefix}/step-transition-3.mp3`,
            `${assetPrefix}/step-transition-4.mp3`,
          ],
          stepTransitionBellPath: `${assetPrefix}/bell.wav`,
        }}
        calculateMetadata={calculateMainMetadata}
      />
      {/* Intro Only - ë™ì  ê¸¸ì´ */}
      <Composition
        id="Intro"
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        component={Intro as any}
        durationInFrames={introDuration}
        fps={30}
        width={1920}
        height={1080}
        defaultProps={{
          channelName: activeConfig.meta.name,
          primaryColor: activeConfig.theme.primaryColor,
          secondaryColor: activeConfig.theme.secondaryColor,
          introSoundPath: `${assetPrefix}/intro.mp3`,
          introBackgroundPath: `${assetPrefix}/intro/background.png`,
          thumbnailPath: `${assetPrefix}/thumbnail.png`,
          targetLanguage: activeConfig.meta.targetLanguage,
          nativeLanguage: activeConfig.meta.nativeLanguage,
          viralNarrationPath: `${assetPrefix}/intro-viral.mp3`,
          viralNarrationDuration: VIRAL_TTS_DURATION,
          guideNarrationPath: `${assetPrefix}/intro-narration.mp3`,
          guideNarrationDuration: GUIDE_TTS_DURATION,
          stepNarrationPaths: [
            `${assetPrefix}/intro-step1.mp3`,
            `${assetPrefix}/intro-step2.mp3`,
            `${assetPrefix}/intro-step3.mp3`,
            `${assetPrefix}/intro-step4.mp3`,
          ],
          stepNarrationDurations: STEP_TTS_DURATIONS,
          closingNarrationPath: `${assetPrefix}/intro-closing.mp3`,
          closingNarrationDuration: CLOSING_TTS_DURATION,
          uiLabels: activeConfig.uiLabels,
        }}
      />
      {/* Step 1: ìë§‰ ì—†ì´ ë“£ê¸° */}
      <Composition
        id="Step1"
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        component={Step1 as any}
        durationInFrames={step1Duration}
        fps={30}
        width={1920}
        height={1080}
        defaultProps={{
          backgroundImage: 'background.png',
          audioFiles: activeAudioFiles,
          title: activeScript.metadata.title.target,
        }}
      />
      {/* Step 2: ë¬¸ì¥ë³„ ë“£ê¸° */}
      <Composition
        id="Step2"
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        component={Step2 as any}
        durationInFrames={step2Duration}
        fps={30}
        width={1920}
        height={1080}
        defaultProps={{
          backgroundImage: 'background.png',
          sentences: activeScript.sentences,
          audioFiles: activeAudioFiles,
          colors: {
            maleText: activeConfig.colors.maleText,
            femaleText: activeConfig.colors.femaleText,
            nativeText: activeConfig.colors.nativeText,
          },
        }}
      />
      {/* Step 3: 10ë²ˆì”© ë°˜ë³µ ë“£ê¸° (Interval Training) */}
      <Composition
        id="Step3"
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        component={Step3 as any}
        durationInFrames={step3Duration}
        fps={30}
        width={1920}
        height={1080}
        defaultProps={{
          backgroundImage: 'background.png',
          sentences: activeScript.sentences,
          audioFiles: activeAudioFiles,
          colors: activeConfig.colors,
          repeatCount: activeConfig.content.repeatCount,
          imageRatio: activeConfig.layout.step3ImageRatio,
          uiLabels: activeConfig.uiLabels,
        }}
      />
      {/* Step 4: ë‹¤ì‹œ ìë§‰ ì—†ì´ ë“£ê¸° */}
      <Composition
        id="Step4"
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        component={Step4 as any}
        durationInFrames={step4Duration}
        fps={30}
        width={1920}
        height={1080}
        defaultProps={{
          backgroundImage: 'background.png',
          audioFiles: activeAudioFiles,
          title: activeScript.metadata.title.target,
        }}
      />
      {/* Step Transitions (ìŠ¤í… ì „í™˜ í™”ë©´) */}
      {[1, 2, 3, 4].map((stepNum) => (
        <Composition
          key={`StepTransition${stepNum}`}
          id={`StepTransition${stepNum}`}
          // eslint-disable-next-line @typescript-eslint/no-explicit-any
          component={StepTransition as any}
          durationInFrames={STEP_TRANSITION_DURATION}
          fps={30}
          width={1920}
          height={1080}
          defaultProps={{
            stepNumber: stepNum,
            ttsPath: `${assetPrefix}/step-transition-${stepNum}.mp3`,
            bellSoundPath: `${assetPrefix}/bell.wav`,
            nativeLanguage: activeConfig.meta.nativeLanguage,
          }}
        />
      ))}
      {/* Ending (ì—”ë”© í™”ë©´) */}
      <Composition
        id="Ending"
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        component={Ending as any}
        durationInFrames={ENDING_DURATION}
        fps={30}
        width={1920}
        height={1080}
        defaultProps={{
          backgroundPath: `${assetPrefix}/intro/background.png`,
          targetLanguage: activeConfig.meta.targetLanguage,
          nativeLanguage: activeConfig.meta.nativeLanguage,
        }}
      />
      {/* Single Sentence Short - Dynamic composition that accepts sentence via inputProps */}
      <Composition
        id="SingleSentenceShort"
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        component={SingleSentenceShort as any}
        durationInFrames={300} // Default, will be overridden by calculateMetadata
        fps={30}
        width={1080}
        height={1920}
        defaultProps={{
          sentence: activeScript.sentences[0],
          audioFile:
            activeAudioFiles.find(
              (af) => af.sentenceId === activeScript.sentences[0]?.id && af.speed === '1.0x'
            ) || activeAudioFiles[0],
          config: activeConfig,
          backgroundImage: 'background.png',
        }}
        calculateMetadata={({ props }) => ({
          durationInFrames: calculateSingleSentenceShortDuration(
            props.audioFile,
            props.introAudioFile
          ),
        })}
      />
      {/* Cat Interview Short - ê³ ì–‘ì´ ì¸í„°ë·° ì˜ì–´ í•™ìŠµ (9:16) */}
      <Composition
        id="CatInterviewShort"
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        component={CatInterviewShort as any}
        durationInFrames={calculateCatInterviewDuration(2)} // 2ê°œ ëŒ€í™” ê¸°ë³¸
        fps={30}
        width={1080}
        height={1920}
        defaultProps={{
          dialogues: [
            { question: '"ëˆˆì´ ì™€ìš”"ëŠ”?', answer: "It's snowing!" },
            { question: '"ì¶”ì›Œìš”"ëŠ”?', answer: "It's cold!" },
          ],
          videoPath: 'cat_interview/2026-01-12/2026-01-12_cat_interview.mp4',
          theme: 'Snowy Day',
          channelName: 'ë‚˜ë¹„ì˜ ì˜ì–´êµì‹¤',
        }}
      />
      ã…£{/* Listening Quiz Short - ì„ íƒì§€ í€´ì¦ˆ í˜•ì‹ (9:16) */}
      <Composition
        id="ListeningQuizShort"
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        component={ListeningQuizShort as any}
        durationInFrames={calculateListeningQuizShortDuration(
          activeAudioFiles.find(
            (af) => af.sentenceId === activeScript.sentences[0]?.id && af.speed === '1.0x'
          )?.duration,
          activeAudioFiles.find(
            (af) => af.sentenceId === activeScript.sentences[0]?.id && af.speed === '0.8x'
          )?.duration
        )}
        fps={30}
        width={1080}
        height={1920}
        defaultProps={{
          sentence: {
            ...activeScript.sentences[0],
            choices: generateQuizChoices(activeScript.sentences[0]),
          },
          audioFile:
            activeAudioFiles.find(
              (af) => af.sentenceId === activeScript.sentences[0]?.id && af.speed === '1.0x'
            ) || activeAudioFiles[0],
          slowAudioFile: activeAudioFiles.find(
            (af) => af.sentenceId === activeScript.sentences[0]?.id && af.speed === '0.8x'
          ),
          config: activeConfig,
          backgroundImage: 'background.png',
          sentenceIndex: 1,
          episodeTitle: activeScript.metadata.title.native,
          audioDuration: activeAudioFiles.find(
            (af) => af.sentenceId === activeScript.sentences[0]?.id && af.speed === '1.0x'
          )?.duration,
          slowAudioDuration: activeAudioFiles.find(
            (af) => af.sentenceId === activeScript.sentences[0]?.id && af.speed === '0.8x'
          )?.duration,
        }}
        calculateMetadata={({ props }) => {
          return {
            durationInFrames: calculateListeningQuizShortDuration(
              props.audioDuration,
              props.slowAudioDuration
            ),
          };
        }}
      />

      {/* ================================================================== */}
      {/* Comparison Longform Compositions (Korean vs Native) */}
      {/* ================================================================== */}

      {/* ComparisonLongform - Full comparison video */}
      <Composition
        id="ComparisonLongform"
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        component={ComparisonLongform as any}
        durationInFrames={calculateComparisonDuration(30, 'normal')} // 30 segments, normal profile
        fps={30}
        width={1920}
        height={1080}
        defaultProps={{
          script: dynamicComparisonScript ?? createSampleComparisonScript('korean-vs-native', 30),
          backgroundImage: 'background.png',
          timingProfile: 'normal' as TimingProfileType,
          selectedHookVariant: 0,
        }}
        calculateMetadata={({ props }) => ({
          durationInFrames: calculateComparisonDuration(
            props.script?.segments?.length ?? 30,
            props.timingProfile ?? 'normal'
          ),
        })}
      />

      {/* ComparisonView - Single segment preview */}
      <Composition
        id="ComparisonView"
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        component={ComparisonView as any}
        durationInFrames={300} // 10 seconds at 30fps
        fps={30}
        width={1920}
        height={1080}
        defaultProps={{
          segment: createSampleComparisonScript('korean-vs-native', 25).segments[0],
          timingProfile: 'normal' as TimingProfileType,
          isBurst: false,
        }}
      />

      {/* HookIntro - Hook intro preview */}
      <Composition
        id="HookIntro"
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        component={HookIntro as any}
        durationInFrames={150} // 5 seconds at 30fps
        fps={30}
        width={1920}
        height={1080}
        defaultProps={{
          hook: createSampleComparisonScript('korean-vs-native', 25).hook,
          hookVariants: createSampleComparisonScript('korean-vs-native', 25).hookVariants,
          selectedVariantIndex: 0,
          backgroundImage: 'background.png',
        }}
      />

      {/* CTAEnding - CTA ending preview */}
      <Composition
        id="CTAEnding"
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        component={CTAEnding as any}
        durationInFrames={450} // 15 seconds at 30fps
        fps={30}
        width={1920}
        height={1080}
        defaultProps={{
          cta: createSampleComparisonScript('korean-vs-native', 25).cta,
          backgroundImage: 'background.png',
        }}
      />
    </>
  );
};
